# 深度学习

## 一.机器学习与深度学习

### 1.机器学习

机器学习是使用算法分析数据，从该数据中学习，然后对新数据做出决定或预测的做法。
与常规代码实现不同的是，通过机器学习，机器不是使用一组特定的指令手动编写代码来完成特定任务，而是使用**数据和算法**对其进行训练，使其能够在**不被明确告知如何执行任务**的情况下执行任务。

**总结：通过数据学习**

### 2.深度学习

深度学习是机器学习的一个子领域，它使用受大脑神经网络结构和功能启发的算法。
并非真正的生物神经网络，而是**人工神经网络**（ANN）。

## 二.人工神经网络

1.人工神经网络是使用我们所说的神经元构建的。
2.人工神经网络中的神经元被组织成我们所说的层。
3.ANN 中的层（除输入层和输出层外的所有层）称为隐藏层。
4.如果 ANN 具有多个隐藏层，则称 ANN 为深度 ANN。

输入层 - 输入数据的每个组件对应一个节点。
隐藏层 - 为每个隐藏层任意选择的节点数。
输出层 - 每个可能的所需输出一个节点。

### 补充：Keras Sequential Model 硬顺序模型

```python
from keras.models import Sequential
from keras.layers import Dense, Activation
model = Sequential(layers)
layers = [
    Dense(units=3, input_shape=(2,), activation='relu'),
    Dense(units=2, activation='softmax')
]
```

单词 dense 表示这些层的类型 `Dense` ，dense称为 **密集层**是一种特殊类型的层。
dense 是 ANN 中最基本的层类型，并且 dense 层的每个输出都是使用该层的每个输入来计算的。

查看我们图像中从隐藏层到输出层的箭头，我们可以看到隐藏层中的每个节点都连接到输出层中的所有节点。这就是我们如何知道图像中的输出层是密集层的方式。同样的逻辑也适用于隐藏层。
传递给每层中的 `Dense` 层构造函数的第一个参数告诉我们它应该有多少个神经元。
输入形状参数 `input_shape=(2,)` 告诉我们输入层有多少个神经元，所以在我们的例子中，我们有两个。
最后，我们有一个所谓的激活函数的参数。

1. `activation='relu'`
2. `activation='softmax'`

softmax函数激活。

## 三.层解释

### 1.层权重

两个节点之间的每个连接都有一个关联的权重，它只是一个数字。
每个权重表示两个节点之间的连接强度。当网络在输入层的给定节点处接收到输入时，该输入将通过连接传递到下一个节点，并且输入将乘以分配给该连接的权重。
**总结：就像特征的参数**

### 2.通过神经网络向前传递

一旦我们获得给定节点的输出，获得的输出就是作为输入传递给下一层节点的值。
输入层到输出层的整个过程称为通过网络的前向传递。
**总结:代入参数和输入进行计算得到输出的过程**

### 3.寻找最佳权重

模型的学习，所有连接处的权重都会得到更新和优化，以便输入数据点映射到正确的输出预测类。
**总结：不断更新找到最佳参数**

### 补充：Keras Sequential Model 硬顺序模型

```python
layers = [
    Dense(units=6, input_shape=(8,), activation='relu'),
    Dense(units=6, activation='relu'),
    Dense(units=4, activation='softmax')
]
from keras.models import Sequential
from keras.layers import Dense, Activation
# 均为连接层
layers = [
    Dense(units=6, input_shape=(8,), activation='relu'),
    Dense(units=6, activation='relu'),
    Dense(units=4, activation='softmax')
]

model = Sequential(layers)
```


请注意，列表中指定的第一个 `Dense` 对象不是输入图层。第一个 `Dense` 对象是第一个隐藏层。输入层被指定为第一个 `Dense` 对象的构造函数的参数。

我们的输入形状是 8。这就是为什么我们的输入形状被指定为 `input_shape=(8,)` 。我们的第一个隐藏层有六个节点，第二个隐藏层也有六个节点，输出层有四个节点。

现在，请注意，我们对两个隐藏层都使用了一个名为 relu `activation='relu'` 的激活函数， `activation='softmax'` 而对于输出层则使用了一个名为 softmax 的激活函数。

**总结：dense作为密集层接受输入，然后代入参数计算得到输出**

## 四.激活函数

### 1.定义

在人工神经网络中，激活函数是将节点的输入映射到其相应输出的函数。
**节点输出 = 激活（输入的加权总和） **  通常是非线性变换

### 2.如逻辑回归函数，我就不摘抄了

### 3.RELU

$$
[ f(x) = \max(0, x) ]
$$

这里的想法是，神经元越积极，它就越被激活。

### 4.原因：

具有非线性激活函数使我们的神经网络能够计算任意复杂的函数。
**总结：非线性更复杂，更具现实意义**

### 5.补充Keras Sequential Model 硬顺序模型

```python
from keras.models import Sequential
from keras.layers import Dense, Activation
model = Sequential([
    Dense(units=5, input_shape=(3,), activation='relu')
])

# 第二种方法
model = Sequential()
model.add(Dense(units=5, input_shape=(3,)))
model.add(Activation('relu'))
```

## 五.训练神经网络

### 1.优化算法

梯度下降等

### 2.损失函数

略略略

### 3.梯度

### 4.学习率

### 5.权重

### 6.补充Keras Sequential Model 硬顺序模型

```python
import keras
from keras.models import Sequential
from keras.layers import Activation
from keras.layers.core import Dense
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy

model = Sequential([
    Dense(units=16, input_shape=(1,), activation='relu'), # 一个输入， 16个神经元， RELU函数
    Dense(units=32, activation='relu'),
    Dense(units=2, activation='sigmoid')
])
"""
输入层：这个模型的输入层没有单独定义，因为输入层会根据后续添加的第一个 Dense 层自动创建。这里指定了输入数据的形状为 (1,)，意味着输入数据是一个包含 1 个特征的向量。

第一个隐藏层：这是一个具有 16 个神经元的全连接层，激活函数为 ReLU。输入特征的维度为 1。

第二个隐藏层：这是一个具有 32 个神经元的全连接层，激活函数为 ReLU。

输出层：这是一个具有 2 个神经元的全连接层，激活函数为 sigmoid。sigmoid 函数常用于二分类问题，它将神经网络的输出压缩到 (0, 1) 范围内，表示两个类别的概率。
"""
model.compile(
    optimizer=Adam(learning_rate=0.0001),  # 学习率
    loss='sparse_categorical_crossentropy', # 交叉熵损失函数
    metrics=['accuracy'] # 准确率
)
"""
优化器：你选择了 Adam 优化器，并设置了学习率为 0.0001。Adam 是一种常用的优化算法，它结合了动量方法和自适应学习率。

损失函数：你选择了稀疏分类交叉熵作为损失函数。这个损失函数通常用于多类别分类问题，特别是当标签是整数形式时，比如 0、1、2 等。

评估指标：你指定了模型在训练和验证过程中要计算的评估指标为准确率（accuracy）。准确率是分类问题中常用的评估指标，表示模型预测正确的样本比例。
"""
model.fit(
    x=scaled_train_samples, # 样本
    y=train_labels, # 标签
    batch_size=10, # 一次穿多少
    epochs=20,  # 传几次
    shuffle=True, # 清洗
    verbose=2 # 看两次日志
)
"""
训练数据 (x) 和标签 (y)：scaled_train_samples 是训练数据，train_labels 是对应的标签。模型将使用这些数据进行训练。

批大小 (batch_size)：你将训练数据分成了批次，每个批次包含了 10 个样本。批大小的选择影响了模型的训练速度和内存消耗。

训练周期数 (epochs)：你设置了训练周期为 20，也就是模型将遍历整个训练数据集 20 次，每次遍历称为一个训练周期。

洗牌 (shuffle)：你设置了数据是否在每个训练周期之前进行洗牌，这样可以增加数据的随机性，有助于模型学习更好的特征。

详细程度 (verbose)：你设置了输出的详细程度为 2，表示每个训练周期结束后输出一行日志，包括训练的进度条和评估指标。

通过这些参数，模型将使用 Adam 优化器来最小化稀疏分类交叉熵损失，对训练数据进行 20 个训练周期的训练，每次训练使用 10 个样本，并且在训练过程中将数据进行洗牌以增加随机性。
"""
```

### 7.损失函数

均方误差
代码

```python
model = Sequential([
    Dense(16, input_shape=(1,), activation='relu'),
    Dense(32, activation='relu'),
    Dense(2, activation='sigmoid')
])
model.compile(
    Adam(learning_rate=.0001), 
    loss='sparse_categorical_crossentropy',  # 均方误差
    metrics=['accuracy']
)
```

### 8.学习率

```python
model = Sequential([
    Dense(units=16, input_shape=(1,), activation='relu'),
    Dense(units=32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),# 正则化
    Dense(units=2, activation='sigmoid')
])

model.compile(
    optimizer=Adam(learning_rate=0.0001), # 设置学习率
    loss='sparse_categorical_crossentropy', 
    metrics=['accuracy']
)
```

### 9.训练集测试集验证集